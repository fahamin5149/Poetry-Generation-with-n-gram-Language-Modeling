{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd097a40",
   "metadata": {
    "id": "fd097a40"
   },
   "source": [
    "## POETRY Generation using N-grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd8420",
   "metadata": {
    "id": "bbfd8420"
   },
   "source": [
    "\n",
    "- Poetry Generation with n-gram Language Modeling:\n",
    "  - This project involves generating poetry using n-gram language modeling techniques.\n",
    "  \n",
    "- Task Description:\n",
    "  - The task is to print three stanzas of poetry with an empty line in between.\n",
    "  - The generation model is trained on a provided Poetry Corpus containing poems from renowned Urdu poets like Faiz, Ghalib, and Iqbal, along with other Urdu poetry scraped from the internet.\n",
    "  \n",
    "- Assignment Task:\n",
    "  - Load the Poetry Corpus and tokenize it to split it into a list of words.\n",
    "  - Generate n-gram models, including unigram and bigram models.\n",
    "  - For each stanza:\n",
    "    - For each verse:\n",
    "      - Generate a random number of words in the range [7...10].\n",
    "      - Select the first word randomly.\n",
    "      - Select subsequent words until the verse is complete.\n",
    "      - Attempt to rhyme the last word with the last word of the previous verse.\n",
    "      - Print the verse.\n",
    "    - Print an empty line after each stanza.\n",
    "    \n",
    "- Implementation Challenges:\n",
    "  - Challenges include selecting subsequent words based on the first word chosen for the verse.\n",
    "  - Conditional Frequency Distribution (CFD) is used to predict the most probable next word.\n",
    "  - Rhyming the generated verses adds complexity, requiring the building of a rhyming dictionary.\n",
    "  - Considering the Urdu sentence structure from right to left, n-gram models are adapted accordingly.\n",
    "  \n",
    "- Standard n-gram Models:\n",
    "  - Develop unigram, bigram, and trigram models using the Conditional Frequency Distribution method.\n",
    "  - Start by selecting the first word randomly and use the bigram model to generate subsequent words until the verse is complete.\n",
    "  - Compare the results of the two n-gram models.\n",
    "  \n",
    "This project showcases proficiency in natural language processing (NLP), specifically in generating poetry using n-gram language modeling techniques applied to Urdu language data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb709115",
   "metadata": {
    "id": "bb709115"
   },
   "outputs": [],
   "source": [
    "# File reading\n",
    "\n",
    "with open('ghalib.txt', 'r', encoding='utf-8') as file:\n",
    "    ghalib_urdu_text = file.read()\n",
    "\n",
    "with open('iqbal.txt', 'r', encoding='utf-8') as file:\n",
    "    iqbal_urdu_text = file.read()\n",
    "\n",
    "combine_urdu=result = ''.join([ghalib_urdu_text, iqbal_urdu_text])\n",
    "#print(combine_urdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebb2bd",
   "metadata": {
    "id": "fbebb2bd"
   },
   "outputs": [],
   "source": [
    "# Words tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "urdu_words = word_tokenize(combine_urdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6b44a",
   "metadata": {
    "id": "d2a6b44a"
   },
   "outputs": [],
   "source": [
    "# Creating ngrams\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk import FreqDist\n",
    "\n",
    "unigrams = list(ngrams(urdu_words, 1))\n",
    "unigram_freq = FreqDist(unigrams)\n",
    "\n",
    "bigrams = list(ngrams(urdu_words, 2))\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "\n",
    "trigrams = list(ngrams(urdu_words, 3))\n",
    "trigram_freq = FreqDist(trigrams)\n",
    "\n",
    "#print(type(unigrams))\n",
    "#print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82eaf85",
   "metadata": {
    "id": "a82eaf85",
    "outputId": "29dc41d8-1de7-4fe9-cec0-65dd2c6f893f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "معدن کو؟ فروغِ جوہرِ تیغ، آب دار\n",
      "معدن کو؟ فروغِ جوہرِ تیغ، آب دار تھا کہ ‘\n",
      "صفا کیش و دل کی ہے کہ ‘ تو نے\n",
      "ہے کہ ‘ تو نے کیا ہے کہ ‘ تو\n",
      "\n",
      "بیاباں نورد تھا کہ ‘ تو نے کیا ہے\n",
      "کشا ہے کہ ‘ تو نے کیا ہے کہ ‘\n",
      "میرے ‘ تو نے کیا ہے کہ\n",
      "بیاباں نورد تھا کہ ‘ تو نے کیا\n",
      "\n",
      "دبا یہ بات کہ ‘ تو نے کیا ہے کہ\n",
      "پیشہ طلبگارِ مرد تھا کہ ‘ تو نے کیا ہے\n",
      "میں ہے کہ ‘ تو نے کیا ہے کہ ‘\n",
      "از نمود کچھ بھی نہیں ہے کہ\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "start_word = random.sample(unigrams, 21)\n",
    "#print (starting_words)\n",
    "starting_words = [item[0] for item in start_word]\n",
    "\n",
    "def verse_generation(model):\n",
    "    verse_length=random.randint(7, 10)\n",
    "    verse = []\n",
    "\n",
    "    current_word=random.choice(starting_words)\n",
    "    verse.append(current_word)\n",
    "#     print('start:',current_word)\n",
    "#     print('verse:',verse)\n",
    "\n",
    "    for _ in range(verse_length-1):\n",
    "        next_words = []\n",
    "        for word in model:\n",
    "            if word[0] == current_word:\n",
    "                next_words.append(word[1])\n",
    "        if not next_words:\n",
    "            break\n",
    "        #print('\\n',next_words,'\\n')\n",
    "        freq_nextword= FreqDist(next_words)\n",
    "        frequent_word_nextword = freq_nextword.max()\n",
    "        current_word = frequent_word_nextword\n",
    "        verse.append(current_word)\n",
    "\n",
    "    return ' '.join(verse)\n",
    "\n",
    "def stanza_generation(n_grams, count_for_verse):\n",
    "    stanza = []\n",
    "    for _ in range(count_for_verse):\n",
    "        stanza.append(verse_generation(n_grams))\n",
    "    return stanza\n",
    "\n",
    "for stanza_number in range(3):\n",
    "    stanza = stanza_generation(bigrams, 4)\n",
    "    for i in stanza:\n",
    "        print(i)\n",
    "    if stanza_number < 2:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43708fa5",
   "metadata": {
    "id": "43708fa5"
   },
   "source": [
    "# Question 3\n",
    " Rule Based Roman Urdu Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f761e",
   "metadata": {
    "id": "2e1f761e"
   },
   "source": [
    "Roman Urdu lacks standard lexicon and usually many spelling variations exist for a given word, e.g., the word zindagi (life) is also written as zindagee, zindagy, zaindagee and zndagi. So, in this question you have to Normalize Roman Urdu words using the following Rules given in the attached Pdf. Your Code works for a complete Sentence or multiple sentences.\n",
    "\n",
    "For Example: zaroori, zaruri, zarori map to the 'zrory'. So zrory becomes the correct word for all representations mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e7159",
   "metadata": {
    "id": "dd7e7159",
    "outputId": "8d30aae2-6a7f-4a0e-f2ae-1294a4c80afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zrory zrory zrory armanIan kryin mra totai hayy hy aih hai ytys hty hdhryd isrladh amyn hdjtyhfdjfty hdfhfjfljd\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sentence=\"zaroori zaruri zarori armaniyyyyyyan karain mara tutai haye hay aeihhhhhh haey ytesssssss htie hdhryd esrladh aaaaamin hdjtyhfdjfti hdfhfjjjjjjfljd\"\n",
    "sentence=sentence.lower()\n",
    "sentence_tokens=word_tokenize(sentence)\n",
    "modified_list=[]\n",
    "\n",
    "for words in sentence_tokens:\n",
    "    if (words.endswith(\"ain\")):\n",
    "        #print(f'if i am true {words}')\n",
    "        words=words.replace('ain','ein')\n",
    "\n",
    "    if(\"ar\" in words[1:]):\n",
    "        words=words.replace('ar','r')\n",
    "        #print(f'if ar i am true {words}')\n",
    "\n",
    "\n",
    "    if(\"ai\" in words):\n",
    "        words=words.replace('ai','ae')\n",
    "        #print(f'if ai i am true {words}')\n",
    "        help=True\n",
    "\n",
    "    if(\"ai\" in words):\n",
    "        words=words.replace('ai','ae')\n",
    "        print(f'if ai i am true {words}')\n",
    "\n",
    "\n",
    "    if (\"iy\" in words):\n",
    "        multi_case=r'iy+y*'\n",
    "        words=re.sub(multi_case,'I',words)\n",
    "        #print(f'if ai i am true {words}')\n",
    "\n",
    "    if (words.endswith(\"ay\")):\n",
    "        #print(f'if ay i am true {words}')\n",
    "        words=words.replace('ay','e')\n",
    "\n",
    "    if (\"ih\" in words):\n",
    "        multi_case=r'ih+h*'\n",
    "        words=re.sub(multi_case,'eh',words)\n",
    "        #print(f'ih ai i am true {words}')\n",
    "\n",
    "    if (words.endswith(\"ey\")):\n",
    "        #print(f'if ey i am true {words}')\n",
    "        words=words.replace('ey','e')\n",
    "\n",
    "    if (\"s\" in words):\n",
    "        multi_case=r's+'\n",
    "        words=re.sub(multi_case,'s',words)\n",
    "        #print(f'if s i am true {words}')\n",
    "\n",
    "    if (words.endswith(\"ie\")):\n",
    "        #print(f'if ie i am true {words}')\n",
    "        words=words.replace('ie','y')\n",
    "\n",
    "    if (\"ry\" in words and not(words.endswith(\"ry\"))):\n",
    "        #print(f'if ri i am true {words}')\n",
    "        words=words.replace('ry','ri')\n",
    "\n",
    "    if (words.startswith(\"es\")):\n",
    "        #print(f'if es i am true {words}')\n",
    "        words=words.replace('es','is')\n",
    "\n",
    "    if(\"a\" in words):\n",
    "        multi_case=r'a+'\n",
    "        words=re.sub(multi_case,\"a\",words)\n",
    "\n",
    "    if (\"ty\" in words and not(words.endswith(\"ty\"))):\n",
    "        #print(f'if ty i am true {words}')\n",
    "        words=words.replace('ty','ti')\n",
    "\n",
    "    if(\"j\" in words):\n",
    "        multi_case=r'j+'\n",
    "        words=re.sub(multi_case,\"j\",words)\n",
    "\n",
    "    if(\"o\" in words):\n",
    "        multi_case=r'o+'\n",
    "        words=re.sub(multi_case,\"o\",words)\n",
    "\n",
    "    if(\"e\" in words):\n",
    "        multi_case=r'e+'\n",
    "        words=re.sub(multi_case,\"i\",words)\n",
    "\n",
    "    if(\"d\" in words):\n",
    "        multi_case=r'd+'\n",
    "        words=re.sub(multi_case,\"d\",words)\n",
    "\n",
    "    if 'u' in words:\n",
    "        words=words.replace('u','o')\n",
    "\n",
    "    if 'i' in words:\n",
    "        pre_case=f'([{string.ascii_lowercase[1:]}])i'\n",
    "        words=re.sub(pre_case,r'\\1y',words)\n",
    "\n",
    "    modified_list.append(words)\n",
    "\n",
    "new_sentence=' '.join(modified_list)\n",
    "print(new_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
